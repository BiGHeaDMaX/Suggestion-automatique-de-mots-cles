{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Approche supervisée**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Lors de l'approche non supervisée, la plus haute proportion de tags correctement prédits (au moins un tag réel prédit) obtenue était de 12.90 %, en gardant en tête que le maximum possible était de 34.92 % (cas où les tags réels sont présents dans le texte du document), puisque ces approches non supervisées sont uniquement basées sur le texte des documents. Nous allons avoir s'il est possible d'améliorer ces résultats avec une approche supervisée.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Éviter les Warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Pour manipuler nos données\n",
    "import pandas as pd\n",
    "\n",
    "# Utilisé dans plusieurs fonctions de préparation des données\n",
    "import numpy as np\n",
    "\n",
    "# Pour les vectorisations de type bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Gensim - Pour la vectorisation de type Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Utilisé pour l'embedding avec Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Utilisé pour l'embedding avec BERT (Hugging Face)\n",
    "from transformers import TFAutoModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Utilisé pour l'embedding avec USE\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Pour réduction dimentionnelle des features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modèles supervisés\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier  # Utilisé avec LinearSVC et LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Mesures de performance des prédictions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "\n",
    "# Utilisé dans la fonction de qualité des prédictions\n",
    "# et pour encoder les tags avant de les passer dans les modèles\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Pour segmenter nos données train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pour rendre les résultats reproductibles (le plus possible)\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "\n",
    "# Mesures de durée d'éxécution\n",
    "# Aussi utilisé dans run_and_eval_model\n",
    "import time\n",
    "\n",
    "# Utilisé lors des sauvagardes et chargement de données/objets\n",
    "import pickle\n",
    "import os  # Aussi utilisé pour connaitre le nombre de CPU\n",
    "\n",
    "# Pour loger les run des modèles\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook fonctionne avec : \n",
    "\n",
    "- Python 3.10.9\n",
    "- Anaconda 23.3.1\n",
    "- Wordcloud 1.9.2\n",
    "- Gensim 4.3.0\n",
    "- Tensorflow 2.10.1\n",
    "- setuptools 68.2.2\n",
    "- mlflow 2.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mesure de la durée d'exécution du notebook : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_notebook = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set d'une seed commune pour des résultats reproductibles, ou pour s'en approcher car le multithreading peut amener un peu de variabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "set_random_seed(seed_value)  # Définit une seed commune pour random, numpy et tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nombre de threads disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers_to_use pourra être utilisé pour les algorithmes qui gèrent le multithreading\n",
    "workers_to_use = os.cpu_count() - 1  # J'en retire 1 pour plus de stabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paramètres pour ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log des exécutions des modèles supervisés\n",
    "# hyperparamètres et métriques\n",
    "do_log_run = False\n",
    "\n",
    "# Enregistrement du modèle entraîné\n",
    "# si le log des exécutions est activé\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1). Importations des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_dl</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-08 21:22:05</td>\n",
       "      <td>[firebase, testing, jest, error, assertion, cl...</td>\n",
       "      <td>[firebase, testing, with, jest, throws, error,...</td>\n",
       "      <td>[firebase, jestjs, reactjs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-08 21:49:08</td>\n",
       "      <td>[block, hack, language, benefit, block, job, w...</td>\n",
       "      <td>[concurrent, block, in, hacklang, since, hack,...</td>\n",
       "      <td>[async-await, concurrency]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-08 21:49:57</td>\n",
       "      <td>[type, function, typescript, function, type, i...</td>\n",
       "      <td>[can, you, set, a, type, for, a, function, in,...</td>\n",
       "      <td>[typescript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-08 21:51:00</td>\n",
       "      <td>[store, service, account, looking, expo, appli...</td>\n",
       "      <td>[expo, eas, submit, where, to, store, service,...</td>\n",
       "      <td>[expo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-08 22:32:53</td>\n",
       "      <td>[store, retrieve, structure, type, c, copying,...</td>\n",
       "      <td>[reliably, and, portably, store, and, retrieve...</td>\n",
       "      <td>[c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46493</th>\n",
       "      <td>2022-03-21 08:52:43</td>\n",
       "      <td>[option, option, know, option, case, option, o...</td>\n",
       "      <td>[how, to, know, if, a, select2, has, options, ...</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46494</th>\n",
       "      <td>2022-03-21 08:54:03</td>\n",
       "      <td>[ring, plot, attempt, gap, use, plot, paint, r...</td>\n",
       "      <td>[matplotlib, how, to, plot, a, closed, ring, i...</td>\n",
       "      <td>[matplotlib, python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46495</th>\n",
       "      <td>2022-03-21 09:02:54</td>\n",
       "      <td>[security, problem, terraform, dependency, loc...</td>\n",
       "      <td>[which, security, problem, does, terraform, ch...</td>\n",
       "      <td>[terraform]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46496</th>\n",
       "      <td>2022-03-21 13:54:21</td>\n",
       "      <td>[studio, creation, blob, container, error, mes...</td>\n",
       "      <td>[visual, studio, 2022, with, azurite, integrat...</td>\n",
       "      <td>[azure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46497</th>\n",
       "      <td>2022-03-21 13:56:22</td>\n",
       "      <td>[pattern, aw, parameter, store, array, appsett...</td>\n",
       "      <td>[use, ioption, pattern, with, aws, parameter, ...</td>\n",
       "      <td>[.net, .net-core, c#]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date                                             corpus  \\\n",
       "0     2022-05-08 21:22:05  [firebase, testing, jest, error, assertion, cl...   \n",
       "1     2022-05-08 21:49:08  [block, hack, language, benefit, block, job, w...   \n",
       "2     2022-05-08 21:49:57  [type, function, typescript, function, type, i...   \n",
       "3     2022-05-08 21:51:00  [store, service, account, looking, expo, appli...   \n",
       "4     2022-05-08 22:32:53  [store, retrieve, structure, type, c, copying,...   \n",
       "...                   ...                                                ...   \n",
       "46493 2022-03-21 08:52:43  [option, option, know, option, case, option, o...   \n",
       "46494 2022-03-21 08:54:03  [ring, plot, attempt, gap, use, plot, paint, r...   \n",
       "46495 2022-03-21 09:02:54  [security, problem, terraform, dependency, loc...   \n",
       "46496 2022-03-21 13:54:21  [studio, creation, blob, container, error, mes...   \n",
       "46497 2022-03-21 13:56:22  [pattern, aw, parameter, store, array, appsett...   \n",
       "\n",
       "                                               corpus_dl  \\\n",
       "0      [firebase, testing, with, jest, throws, error,...   \n",
       "1      [concurrent, block, in, hacklang, since, hack,...   \n",
       "2      [can, you, set, a, type, for, a, function, in,...   \n",
       "3      [expo, eas, submit, where, to, store, service,...   \n",
       "4      [reliably, and, portably, store, and, retrieve...   \n",
       "...                                                  ...   \n",
       "46493  [how, to, know, if, a, select2, has, options, ...   \n",
       "46494  [matplotlib, how, to, plot, a, closed, ring, i...   \n",
       "46495  [which, security, problem, does, terraform, ch...   \n",
       "46496  [visual, studio, 2022, with, azurite, integrat...   \n",
       "46497  [use, ioption, pattern, with, aws, parameter, ...   \n",
       "\n",
       "                              tags  \n",
       "0      [firebase, jestjs, reactjs]  \n",
       "1       [async-await, concurrency]  \n",
       "2                     [typescript]  \n",
       "3                           [expo]  \n",
       "4                              [c]  \n",
       "...                            ...  \n",
       "46493         [javascript, jquery]  \n",
       "46494         [matplotlib, python]  \n",
       "46495                  [terraform]  \n",
       "46496                      [azure]  \n",
       "46497        [.net, .net-core, c#]  \n",
       "\n",
       "[46498 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data_clean.pkl', 'rb') as fichier:\n",
    "    data = pickle.load(fichier)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Option d'échantillonages pour la réalisation de tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas d'échantillonnage.\n"
     ]
    }
   ],
   "source": [
    "echantillon = False\n",
    "taille_echantillon = 15000\n",
    "\n",
    "if echantillon:\n",
    "    data = data.sample(taille_echantillon, random_state=seed_value)  # random_state car en fonction de l'échantillonage\n",
    "                                                                     # les résultats peuvent changer et pour pouvoir\n",
    "                                                                     # comparer nos tunings d'hyperparamètres, nous devons\n",
    "                                                                     # avoir des résultats reproductibles\n",
    "\n",
    "    data\n",
    "else:\n",
    "    print(\"Pas d'échantillonnage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2). Vectorisations du corpus de type <i>Bag Of Words</i>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A). Vectorisations de type <i>bag-of-words</i> classique**\n",
    "\n",
    "Nous utilisons *data['corpus']*, le corpus avec traitement complet (suppression des stopwords, des mots rares, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations (documents) : 46498\n",
      "Nombre de variables (features) : 500\n",
      "Premier document vectorisé (100 premières features) :\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Chaque document de data['corpus'] est sous la forme d'une liste de mot.\n",
    "# CountVectorizer() prend en entrée un string. Nous allons donc concaténer chaque document.\n",
    "preprocessed_corpus = [' '.join(doc) for doc in data['corpus']]\n",
    "\n",
    "# max_features : ne retenir que les x mots les plus fréquents\n",
    "# Sans cette limite, le nombre de features serait égal\n",
    "# au nombre de mots dans le vocabulaire\n",
    "max_features = 500\n",
    "\n",
    "# Création de CountVectorizer et vectorisation des données textuelles\n",
    "vectorizer_count = CountVectorizer(max_features=max_features)\n",
    "vectorized_corpus_count = vectorizer_count.fit_transform(preprocessed_corpus)\n",
    "\n",
    "# Afficher les caractéristiques de la matrice vectorisée\n",
    "print(f\"Nombre d'observations (documents) : {vectorized_corpus_count.shape[0]}\")\n",
    "print(f\"Nombre de variables (features) : {vectorized_corpus_count.shape[1]}\")\n",
    "print(\"Premier document vectorisé (100 premières features) :\")\n",
    "print(vectorized_corpus_count.toarray()[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Réduction dimentionnelle de la vectorisation *bag-of-words* classique, qui comporte 500 features, à l'aide d'une ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage cumulatif d'inertie expliqué : 91.03%\n"
     ]
    }
   ],
   "source": [
    "pca_bow = PCA(n_components=300)\n",
    "vectorized_corpus_count_reduced = pca_bow.fit_transform(vectorized_corpus_count.toarray())  # .toarray() car vectorized_corpus_count\n",
    "                                                                                        # est une matrice creuse qui ne peut pas\n",
    "                                                                                        # être traitée telle quelle pour l'ACP\n",
    "\n",
    "# Pourcentage d'inertie expliqué par chaque composante\n",
    "explained_variance_ratio = pca_bow.explained_variance_ratio_\n",
    "\n",
    "# Pourcentage cumulatif d'inertie expliqué\n",
    "cumulative_explained_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(f\"Pourcentage cumulatif d'inertie expliqué : {cumulative_explained_variance_ratio[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B). Vectorisations de type <i>bag-of-words</i> TF-IDF**\n",
    "\n",
    "Nous utilisons encore *data['corpus']*, le corpus avec traitement complet (suppression des stopwords, des mots rares, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations (documents) : 46498\n",
      "Nombre de variables (features) : 500\n",
      "Premier document vectorisé (100 premières features) :\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20109768\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16017539 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09734    0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11521863\n",
      " 0.         0.         0.         0.13373622 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# max_features : ne retenir que les x mots les plus fréquents\n",
    "# Sans cette limite, le nombre de features serait égal\n",
    "# au nombre de mots dans le vocabulaire\n",
    "max_features = 500\n",
    "\n",
    "# Création de TfidfVectorizer et vectorisation des données textuelles\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=max_features)\n",
    "vectorized_corpus_ftidf = vectorizer_tfidf.fit_transform(preprocessed_corpus)  # On réutilise preprocessed_corpus crée lors\n",
    "                                                                               # de la vectorisation BoW classique\n",
    "\n",
    "# Afficher les caractéristiques de la matrice vectorisée\n",
    "print(f\"Nombre d'observations (documents) : {vectorized_corpus_ftidf.shape[0]}\")\n",
    "print(f\"Nombre de variables (features) : {vectorized_corpus_ftidf.shape[1]}\")\n",
    "print(\"Premier document vectorisé (100 premières features) :\")\n",
    "print(vectorized_corpus_ftidf.toarray()[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Réduction dimentionnelle de la vectorisation *bag-of-words* TF-IDF, qui comporte 500 features, à l'aide d'une ACP. Ici, nous devrons garder 400 features pour conserver plus de 90% de l'inertie, la réduction n'est donc pas très efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage cumulatif d'inertie expliqué : 93.27%\n"
     ]
    }
   ],
   "source": [
    "pca_tfidf = PCA(n_components=400)\n",
    "vectorized_corpus_ftidf_reduced = pca_tfidf.fit_transform(vectorized_corpus_ftidf.toarray())  # .toarray() car vectorized_corpus_ftidf\n",
    "                                                                                        # est une matrice creuse qui ne peut pas\n",
    "                                                                                        # être traitée telle quelle pour l'ACP\n",
    "\n",
    "# Pourcentage d'inertie expliqué par chaque composante\n",
    "explained_variance_ratio = pca_tfidf.explained_variance_ratio_\n",
    "\n",
    "# Pourcentage cumulatif d'inertie expliqué\n",
    "cumulative_explained_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(f\"Pourcentage cumulatif d'inertie expliqué : {cumulative_explained_variance_ratio[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3). Vectorisations de type <i>Word/Sentence Embedding</i>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A). Word2Vec**\n",
    "\n",
    "Nous utilisons de nouveau *data['corpus']*, le corpus avec traitement complet (suppression des stopwords, des mots rares, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de démarrer, regardons les tailles des documents de notre corpus avec traitement complet (data['corpus']), ceci va nous servir par la suite : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du plus court document est : 1\n",
      "La taille du plus long document est : 846\n",
      "La taille moyenne des documents est : 26.3\n",
      "75% des documents ont une longueur <= à 32.0 mots.\n"
     ]
    }
   ],
   "source": [
    "min_length = min(len(document) for document in data['corpus'])\n",
    "\n",
    "# Afficher la taille de la plus grande liste\n",
    "print(f\"La taille du plus court document est : {min_length}\")\n",
    "\n",
    "max_length = max(len(document) for document in data['corpus'])\n",
    "\n",
    "# Afficher la taille de la plus grande liste\n",
    "print(f\"La taille du plus long document est : {max_length}\")\n",
    "\n",
    "# Calculer la taille moyenne\n",
    "average_length = sum(len(document) for document in data['corpus']) / len(data['corpus'])\n",
    "\n",
    "# Afficher la taille moyenne\n",
    "print(f\"La taille moyenne des documents est : {average_length:.1f}\")\n",
    "\n",
    "# Afficher Q3 (75e percentile)\n",
    "q3_length = np.percentile([len(document) for document in data['corpus']], 75)\n",
    "print(f\"75% des documents ont une longueur <= à {q3_length} mots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.boxplot([len(document) for document in data['corpus']], vert=False, showfliers=False)\n",
    "plt.title(f\"\\nTailles des documents\\n\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choix entre CBOW et Skip-gram à utiliser dans Word2Vec.\n",
    "\n",
    "**CBOW (Continuous Bag of Words) :** vise à prédire un mot étant donné son contexte, c'est-à-dire étant donné les mots qui en sont proches dans le texte. S'entraîne plus rapidement que Skip-Gram (mieux adapté pour des dataset volumineux) et peut mieux représenter les mots plus fréquents.\n",
    "\n",
    "**Skip-gram :** architecture symétrique visant à prédire les mots du contexte étant donné un mot en entrée. Fonctionne bien avec de petits datsets et peut mieux représenter les mots moins fréquents.\n",
    "\n",
    "Dans notre cas, notamment en raison de la taille du dataset, nous utiliserons **CBOW**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création et entraînement du modèle Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un modèle entraîné précédemment enregistré a été trouvé, chargement de ce dernier.\n",
      "Si vous souhaitez réentraîner le modèle, supprimez le fichier w2v_model_trained.pkl\n",
      "Taille du vocabulaire : 3707\n"
     ]
    }
   ],
   "source": [
    "# Paramètres à passer dans le modèle : \n",
    "\n",
    "w2v_size = 100  # Taille max des vecteurs\n",
    "w2v_window = 5  # Taille du contexte\n",
    "w2v_min_count = 1  # Minimum d'occurences d'un mot pour être pris en compte\n",
    "w2v_epochs = 50  # Nombre de passes sur tout le corpus\n",
    "\n",
    "documents = data['corpus']\n",
    "\n",
    "############################\n",
    "# Enregistrement du modèle #\n",
    "############################\n",
    "\n",
    "nom_fichier_w2v = 'w2v_model_trained'\n",
    "\n",
    "# Si le modèle (entraîné) avait été enregistré, charger ce dernier.\n",
    "if os.path.isfile(f'{nom_fichier_w2v}.pkl') == True and not echantillon:  # Seulement quand on travaille avec le dataset complet\n",
    "    print(f\"Un modèle entraîné précédemment enregistré a été trouvé, chargement de ce dernier.\\nSi vous souhaitez réentraîner le modèle, supprimez le fichier {nom_fichier_w2v}.pkl\")\n",
    "    with open(f'{nom_fichier_w2v}.pkl', 'rb') as fichier:\n",
    "        w2v_model = pickle.load(fichier)\n",
    "# Sinon, entraîner le modèle et l'enregistrer\n",
    "else:\n",
    "    # Création et entraînement du modèle Word2Vec\n",
    "\n",
    "    print(\"Création et entraînement du modèle Word2Vec...\")\n",
    "    w2v_model = Word2Vec(min_count=w2v_min_count,\n",
    "                        window=w2v_window,\n",
    "                        vector_size=w2v_size,\n",
    "                        sg=0,  # 0 : CBOX, 1 : Skipgram\n",
    "                        seed=seed_value,  # Paramétrage de la seed pour des résultats plus reproductibles\n",
    "                        workers= 1 # Pour du multithreading pour accélérer les calculs, utiliser workers_to_use.\n",
    "                                   # Mais attention, utiliser plusieurs threads amène une légère variabilité\n",
    "                                   # en raison des variations de l'ordonnancement des threads du\n",
    "                                   # système d'exploitation. Pour des résultats parfaitement reproductibles,\n",
    "                                   # utiliser un seul worker.\n",
    "    )\n",
    "\n",
    "    w2v_model.build_vocab(documents)\n",
    "\n",
    "    w2v_model.train(documents,\n",
    "                    total_examples=w2v_model.corpus_count,\n",
    "                    epochs=w2v_epochs\n",
    "    )\n",
    "    \n",
    "    print(\"Word2Vec entraîné\")\n",
    "    \n",
    "    # Enregistrement du modèle entraîné\n",
    "    if not echantillon:  # On sauvegarde seulement quand on travaille avec le dataset complet\n",
    "        with open(f'{nom_fichier_w2v}.pkl', 'wb') as fichier:\n",
    "            pickle.dump(w2v_model, fichier)\n",
    "        print(f\"Modèle entraîné enregistré dans le fichier {nom_fichier_w2v}.pkl\")\n",
    "\n",
    "\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Taille du vocabulaire : %i\" % len(w2v_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test du modèle entraîné pour vérifier qu'il a réussi à capter les similarités entre les mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots similaires à 'python' :\n",
      "\n",
      "pip : 0.4790\n",
      "pyenv : 0.4386\n",
      "modulenotfounderror : 0.4354\n",
      "r : 0.4190\n",
      "poetry : 0.4116\n",
      "interpreter : 0.4012\n",
      "pypi : 0.3976\n",
      "setuptool : 0.3963\n",
      "pycharm : 0.3945\n",
      "online : 0.3943\n",
      "\n",
      "--------------------\n",
      "\n",
      "Similarité entre 'python' et 'virtualenv' : 0.3835\n",
      "\n",
      "--------------------\n",
      "\n",
      "L'intrus parmi ces mots ['python', 'javascript', 'image'] est : 'image'.\n"
     ]
    }
   ],
   "source": [
    "# Mots similaires à un mot donné\n",
    "mot_a_tester = \"python\"\n",
    "print(f\"Mots similaires à '{mot_a_tester}' :\\n\")\n",
    "similar_words = w2v_model.wv.most_similar(positive=[mot_a_tester])\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word} : {similarity:.4f}\")\n",
    "\n",
    "print(\"\\n--------------------\\n\")\n",
    "\n",
    "# Similarité entre deux mots\n",
    "mot_a_tester_1 = \"python\"\n",
    "mot_a_tester_2 = \"virtualenv\"\n",
    "similarite = w2v_model.wv.similarity(mot_a_tester_1, mot_a_tester_2)\n",
    "print(f\"Similarité entre '{mot_a_tester_1}' et '{mot_a_tester_2}' : {similarite:.4f}\")\n",
    "\n",
    "print(\"\\n--------------------\\n\")\n",
    "\n",
    "# Trouver l'intrus\n",
    "mot_intrus_1 = \"python\"\n",
    "mot_intrus_2 = \"javascript\"\n",
    "mot_intrus_3 = \"image\"\n",
    "intrus = w2v_model.wv.doesnt_match([mot_intrus_1, mot_intrus_2, mot_intrus_3])\n",
    "print(f\"L'intrus parmi ces mots ['{mot_intrus_1}', '{mot_intrus_2}', '{mot_intrus_3}'] est : '{intrus}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Cela semble assez cohérent. Le modèle semble avoir réussi à capter les similarités entre les mots.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Préparation des documents (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Tokenizer ...\n",
      "Nombre de mots uniques : 3708\n",
      "Premier document encodé :\n",
      "[ 245  290 1561    2  935   13  222  290   27   11  245   36   39  161\n",
      "   40  245    2   36 1627  245  167    3  245   66   27  313  463    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100  # Cette valeur apporte de meilleurs résultat que\n",
    "              # int(q3_length) : valeur du 75e percentile des tailles des documents (calculé précédemment)\n",
    "              # int(average_length) : taille moyenne des documents (calculé précédemment)\n",
    "\n",
    "# On réutilise documents (défini lors de la création et entraînement du modèle Word2Vec),\n",
    "# documents contient data['corpus']\n",
    "print(\"Fit Tokenizer ...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(documents)\n",
    "x_documents = pad_sequences(tokenizer.texts_to_sequences(documents),\n",
    "                            maxlen=maxlen,  # On ne prend que les maxlen premiers mots de chaque document\n",
    "                            padding='post'  # Si le document est plus petit que maxlen, on complète avec des 0\n",
    ") \n",
    "                                                   \n",
    "num_words = len(tokenizer.word_index) + 1  # + 1 : on ajoute 1 pour inclure un index supplémentaire.\n",
    "                                           # Cet index supplémentaire est ajouté pour tenir compte des mots inconnus\n",
    "                                           # qui n'apparaissent pas dans le jeu de données d'entraînement initial.\n",
    "                                           \n",
    "print(\"Nombre de mots uniques : %i\" % num_words)\n",
    "print(\"Premier document encodé :\")\n",
    "print(x_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création de la matrice d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de la matrice d'embedding...\n",
      "Taux d'intégration de mots : 1.0\n",
      "Dimensions de la matrice d'embedding : (3708, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Création de la matrice d'embedding...\")\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1  # + 1 pour les même raisons que précédemment.\n",
    "embedding_matrix = np.zeros((vocab_size, w2v_size))  # w2v_size a été déterminé à la création et\n",
    "                                                     # entraînement du modèle Word2Vec, pour représenter\n",
    "                                                     # la taille max des vecteurs. La matrice qu'on crée ici\n",
    "                                                     # doit avoir la même \"largeur\".\n",
    "\n",
    "i=0\n",
    "j=0   \n",
    "for word, idx in word_index.items():\n",
    "    i +=1\n",
    "    if word in w2v_words:\n",
    "        j +=1\n",
    "        embedding_vector = model_vectors[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = model_vectors[word]\n",
    "            \n",
    "word_rate = np.round(j/i,4)  # Taux d'intégration de mots : Ce taux indique la proportion de mots du corpus\n",
    "                             # pour lesquels un vecteur d'embedding a été trouvé dans le modèle Word2Vec.\n",
    "                             # Un taux élevé suggère que la plupart des mots du corpus ont été trouvés dans\n",
    "                             # le modèle Word2Vec, ce qui signifie que la couverture du modèle d'embedding\n",
    "                             # est suffisamment large pour représenter le vocabulaire du corpus. \n",
    "\n",
    "print(\"Taux d'intégration de mots :\", word_rate)\n",
    "print(f\"Dimensions de la matrice d'embedding : {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le taux d'intégration de mots est bon, la couverture du modèle d'embedding est suffisamment large pour représenter le vocabulaire du corpus.<br>\n",
    "En fixant *w2v_min_count* à 1 (minimum d'occurences d'un mot pour être pris en compte) lors de l'étape d'entraînement du modèle Word2Vec, on s'attend à un taux d'intégration de mots maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création du modèle d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 100)          370800    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 100)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,800\n",
      "Trainable params: 370,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle\n",
    "\n",
    "input = Input(shape=(len(x_documents), maxlen),  # On réutilise le même maxlen\n",
    "                                                 # que celui défini lors de la préparation\n",
    "                                                 # des documents (tokenization)\n",
    "            dtype='float64'\n",
    ")\n",
    "\n",
    "word_input = Input(shape=(maxlen,),dtype='float64')\n",
    "\n",
    "word_embedding = Embedding(input_dim=vocab_size,\n",
    "                           output_dim=w2v_size,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length=maxlen)(word_input)\n",
    "\n",
    "word_vec=GlobalAveragePooling1D()(word_embedding)\n",
    "\n",
    "embed_model = Model([word_input],word_vec)\n",
    "\n",
    "embed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exécution du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de 'word2vec_embedded' : (46498, 100)\n",
      "Premier document encodé :\n",
      "[ 0.00969069  0.01321123 -0.04480806  0.01788921  0.05010077 -0.03574872\n",
      "  0.28900322  0.2242672  -0.14532755  0.13428308  0.2096692   0.06750458\n",
      " -0.24592896 -0.1534113  -0.17026216 -0.01465662 -0.08112413  0.24050009\n",
      " -0.00063547  0.02759812  0.3631919  -0.00303705 -0.2189009  -0.10132784\n",
      "  0.01524056  0.09774195 -0.03866203 -0.1955285   0.11311232 -0.13304017\n",
      "  0.07220504 -0.29820132  0.01475078  0.03793701  0.00285432 -0.07667759\n",
      " -0.16699784 -0.16624227  0.01130853 -0.02775044 -0.09789311 -0.06757158\n",
      " -0.34855935 -0.02401404  0.03611669  0.14539246  0.05993536  0.11015394\n",
      "  0.00735351 -0.0581399   0.146653    0.11877933  0.36097878  0.2443562\n",
      "  0.22058658  0.03172379  0.17728853 -0.11030269  0.04064707  0.06090025\n",
      "  0.07208482  0.01733155 -0.06616202  0.14326526  0.05387218  0.19548507\n",
      "  0.01357756  0.043      -0.11071533 -0.21463135  0.04357689 -0.08674095\n",
      " -0.04625629  0.0280135   0.22280087  0.04288813  0.0849941   0.14862609\n",
      "  0.19736043 -0.27233666 -0.03841544  0.09173156  0.14251514 -0.02095453\n",
      "  0.0126499  -0.05418545 -0.11217298  0.17656887 -0.23021866  0.14075959\n",
      "  0.1782835   0.03375659  0.06308135 -0.20294827 -0.01602705  0.03081683\n",
      " -0.22457115 -0.12445143  0.25150925  0.14098224]\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedded = embed_model.predict(x_documents, verbose=0)\n",
    "print(f\"Dimensions de 'word2vec_embedded' : {word2vec_embedded.shape}\")\n",
    "print(\"Premier document encodé :\")\n",
    "print(word2vec_embedded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B). BERT (Bidirectional Encoder Representations from Transformers - Version de HuggingFace)**\n",
    "\n",
    "- Nous utilisons *data['corpus_dl']*, le corpus avec traitement minimal (uniquement suppression des balises HTML, du code, de la ponctuation et passage en minuscules).\n",
    "- Nous utiliserons le modèle préentraîné *bert-base-uncased*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonction de préparation des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
    "    input_ids=[]\n",
    "    token_type_ids = []\n",
    "    attention_mask=[]\n",
    "    bert_inp_tot = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens = True,\n",
    "                                              max_length = max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask = True, \n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "    \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
    "                             bert_inp['token_type_ids'][0], \n",
    "                             bert_inp['attention_mask'][0]))\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonction de création des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_BERT_fct(model, model_type, sentences, max_length, b_size):\n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    time1 = time.time()\n",
    "    last_hidden_states_tot = None\n",
    "\n",
    "    for step in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[step:step + batch_size]\n",
    "        if not batch_sentences:  # Vérifier si la liste est vide\n",
    "            continue\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(batch_sentences, bert_tokenizer, max_length)\n",
    "        \n",
    "        outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "                    \n",
    "        if last_hidden_states_tot is None:\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "        else:\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot, last_hidden_states))\n",
    "    \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    time2 = np.round(time.time() - time1, 0)\n",
    "    print(f\"Durée du traitement : {time2} s.\")\n",
    "     \n",
    "    return features_bert, last_hidden_states_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un corpus vectorisé précédemment enregistré a été trouvé, chargement de ce dernier.\n",
      "Si vous souhaitez en produire un nouveau, supprimez le fichier corpus_BERT_base.pkl\n",
      "Dimensions de 'features_bert' : (46498, 768)\n",
      "Premier document encodé (100 premières features) :\n",
      "[-0.02556176  0.19166619  0.13080832 -0.14533731  0.23192279 -0.23390609\n",
      "  0.27231774  0.25221944  0.16529511 -0.12145934  0.0659398  -0.14643262\n",
      " -0.33279145  0.14341973 -0.15929255  0.00929002  0.2015008   0.08399679\n",
      "  0.02982539  0.23026131  0.29575825 -0.05759588 -0.3690429   0.03308808\n",
      "  0.44189963  0.01144834  0.239389   -0.15979534 -0.56839114 -0.13160312\n",
      "  0.3315953   0.19866315  0.2921474  -0.19504544 -0.27311787  0.06223141\n",
      " -0.01483567 -0.11062288  0.02103019  0.24610347 -0.33306476 -0.54891557\n",
      "  0.356569    0.01045101  0.07970545 -0.06478487  0.03056774  0.07713743\n",
      "  0.06517577  0.16926381 -0.6254287   0.5211275  -0.08492912  0.08516291\n",
      "  0.28313196  0.31063607  0.21442682 -0.78507257 -0.21066892 -0.28344142\n",
      "  0.3942327  -0.196574    0.06627845 -0.11069189  0.2553069   0.2978554\n",
      "  0.08883379  0.49678004 -0.76545995  0.00800104  0.03436791  0.1454495\n",
      " -0.25624016 -0.28719172 -0.05119082  0.02927    -0.34661153  0.27079555\n",
      "  0.07644089 -0.17478871 -0.21893135  0.09997967 -0.007148    0.2943142\n",
      "  0.3502513  -0.20369798  0.2811486   0.39921075 -0.35352612  0.3357421\n",
      "  0.05475528 -0.1404733   0.08314459  0.14767429  0.3106176   0.14940147\n",
      " -0.3018379   0.25600338  0.09003612  0.19065928]\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Enregistrement du corpus vectorisé avec BERT   #\n",
    "# Car il est très long à produire (env 130 min)  #\n",
    "##################################################\n",
    "\n",
    "nom_fichier_corpus_bert = 'corpus_BERT_base'\n",
    "\n",
    "# Si le corpus (vectorisé avec BERT) avait été enregistré, charger ce dernier.\n",
    "if os.path.isfile(f'{nom_fichier_corpus_bert}.pkl') == True and not echantillon:  # Seulement quand on travaille avec le dataset complet\n",
    "    print(f\"Un corpus vectorisé précédemment enregistré a été trouvé, chargement de ce dernier.\\nSi vous souhaitez en produire un nouveau, supprimez le fichier {nom_fichier_corpus_bert}.pkl\")\n",
    "    with open(f'{nom_fichier_corpus_bert}.pkl', 'rb') as fichier:\n",
    "        features_bert = pickle.load(fichier)\n",
    "# Sinon, production du corpus vectorisé avec le modèle BERT et l'enregistrer\n",
    "else:\n",
    "    documents_dl = [' '.join(doc) for doc in data['corpus_dl']]  # Conversion des documents en un string unique\n",
    "                                                                 # pour pouvoir être passé dans le modèle\n",
    "    max_length = 64\n",
    "    batch_size = 10\n",
    "    model_type = 'bert-base-uncased'  # Utilisation du modèle BERT préentraîné classique\n",
    "    model = TFAutoModel.from_pretrained(model_type)\n",
    "    \n",
    "    features_bert, last_hidden_states_tot = feature_BERT_fct(model,\n",
    "                                                             model_type,\n",
    "                                                             documents_dl, \n",
    "                                                             max_length,\n",
    "                                                             batch_size\n",
    "                                            )\n",
    "    \n",
    "    # Enregistrement du corpus vectorisé avec BERT\n",
    "    if not echantillon:  # On sauvegarde seulement quand on travaille avec le dataset complet\n",
    "        with open(f'{nom_fichier_corpus_bert}.pkl', 'wb') as fichier:\n",
    "            pickle.dump(features_bert, fichier)\n",
    "        print(f\"Corpus vectorisé avec BERT enregistré dans le fichier {nom_fichier_corpus_bert}.pkl\")\n",
    "\n",
    "print(f\"Dimensions de 'features_bert' : {features_bert.shape}\")\n",
    "print(\"Premier document encodé (100 premières features) :\")\n",
    "print(features_bert[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Réduction dimentionnelle de la vectorisation BERT, qui comporte 768 features, à l'aide d'une ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage cumulatif d'inertie expliqué : 92.00%\n"
     ]
    }
   ],
   "source": [
    "pca_bert = PCA(n_components=200)\n",
    "features_bert_reduced = pca_bert.fit_transform(features_bert)\n",
    "\n",
    "# Pourcentage d'inertie expliqué par chaque composante\n",
    "explained_variance_ratio = pca_bert.explained_variance_ratio_\n",
    "\n",
    "# Pourcentage cumulatif d'inertie expliqué\n",
    "cumulative_explained_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(f\"Pourcentage cumulatif d'inertie expliqué : {cumulative_explained_variance_ratio[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C). USE (Universal Sentence Encoder)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fonction de création de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    time1 = time.time()\n",
    "    remaining_sentences = len(sentences) % batch_size\n",
    "    features = []\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step == 0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    # Ajout des lignes restantes si le nombre de documents\n",
    "    # n'est pas un multiple de batch_size\n",
    "    if remaining_sentences > 0:\n",
    "        feat = embed(sentences[-remaining_sentences:])\n",
    "        features = np.concatenate((features, feat))\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "\n",
    "    print(f\"Durée du traitement : {time2} s.\")\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Création des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un corpus vectorisé précédemment enregistré a été trouvé, chargement de ce dernier.\n",
      "Si vous souhaitez en produire un nouveau, supprimez le fichier corpus_USE.pkl\n",
      "Dimensions de 'features_USE' : (46498, 512)\n",
      "Premier document encodé (100 premières features) :\n",
      "[-0.04094313 -0.0475272  -0.03763066  0.0040827   0.02230911  0.03880174\n",
      "  0.04704151  0.02561064  0.04544941  0.04325652  0.04316631 -0.06045892\n",
      "  0.05608445  0.06192103 -0.06235017  0.0624683   0.04258667  0.02278395\n",
      "  0.04786707  0.0266323   0.04511223  0.05755966 -0.06108991 -0.02969537\n",
      " -0.01397429  0.06109723  0.03212766 -0.02867802 -0.04171851 -0.05756116\n",
      " -0.03186219 -0.05645018 -0.01191588 -0.03984817 -0.06119167 -0.03927087\n",
      "  0.01040472 -0.06174475 -0.0148376  -0.05566476  0.06150331  0.03454949\n",
      "  0.01527799  0.02529859  0.06246678 -0.00970078 -0.06156128  0.01057807\n",
      "  0.02672317 -0.06194095  0.00770416  0.06175239  0.04885701 -0.04804653\n",
      " -0.06234592 -0.0584278  -0.05800309 -0.02946029  0.01381144  0.02383122\n",
      " -0.05965327 -0.0595246  -0.01004067  0.04988402 -0.00674931 -0.06060086\n",
      " -0.01254009  0.04228132 -0.06146846 -0.05204443 -0.06246127  0.03736096\n",
      "  0.03187687 -0.01735075 -0.00078161 -0.03492593  0.00726965  0.01888852\n",
      "  0.04289167  0.06164254  0.05476012  0.00591311 -0.06048146 -0.05511801\n",
      "  0.06152225 -0.01491967 -0.04343055 -0.04393582  0.06153398  0.05568598\n",
      "  0.04705812  0.04532878  0.04888884  0.05766375  0.05100977  0.02149096\n",
      "  0.05466684 -0.00125241 -0.0604635  -0.06246451]\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Enregistrement du corpus vectorisé avec USE #\n",
    "# pour ne pas tout recalculer à chaque run    #\n",
    "###############################################\n",
    "\n",
    "nom_fichier_corpus_use = \"corpus_USE\"\n",
    "\n",
    "# Si le corpus (vectorisé avec USE) avait été enregistré, charger ce dernier.\n",
    "if os.path.isfile(f'{nom_fichier_corpus_use}.pkl') == True and not echantillon:  # Seulement quand on travaille avec le dataset complet\n",
    "    print(f\"Un corpus vectorisé précédemment enregistré a été trouvé, chargement de ce dernier.\\nSi vous souhaitez en produire un nouveau, supprimez le fichier {nom_fichier_corpus_use}.pkl\")\n",
    "    with open(f'{nom_fichier_corpus_use}.pkl', 'rb') as fichier:\n",
    "        features_USE = pickle.load(fichier)\n",
    "# Sinon, production du corpus vectorisé avec le modèle USE et l'enregistrer\n",
    "else:\n",
    "    documents_dl = [' '.join(doc) for doc in data['corpus_dl']]  # Conversion des documents en un string unique\n",
    "                                                                 # pour pouvoir être passé dans le modèle\n",
    "\n",
    "    # Chargement du modèle préentraîné\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    features_USE = feature_USE_fct(documents_dl, batch_size)\n",
    "    \n",
    "    # Enregistrement du corpus vectorisé avec BERT\n",
    "    if not echantillon:  # On sauvegarde seulement quand on travaille avec le dataset complet\n",
    "        with open(f'{nom_fichier_corpus_use}.pkl', 'wb') as fichier:\n",
    "            pickle.dump(features_USE, fichier)\n",
    "        print(f\"Corpus vectorisé avec USE enregistré dans le fichier {nom_fichier_corpus_use}.pkl\")\n",
    "\n",
    "print(f\"Dimensions de 'features_USE' : {features_USE.shape}\")\n",
    "print(\"Premier document encodé (100 premières features) :\")\n",
    "print(features_USE[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Réduction dimentionnelle de la vectorisation USE, qui comporte 512 features, à l'aide d'une ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage cumulatif d'inertie expliqué : 94.17%\n"
     ]
    }
   ],
   "source": [
    "pca_use = PCA(n_components=200)\n",
    "features_USE_reduced = pca_use.fit_transform(features_USE)\n",
    "\n",
    "# Pourcentage d'inertie expliqué par chaque composante\n",
    "explained_variance_ratio = pca_use.explained_variance_ratio_\n",
    "\n",
    "# Pourcentage cumulatif d'inertie expliqué\n",
    "cumulative_explained_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "print(f\"Pourcentage cumulatif d'inertie expliqué : {cumulative_explained_variance_ratio[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4). Récupitulatif des vectorisations crées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Bag of words classique : 'vectorized_corpus_count' | Nombre de features : 500\n",
      "- Bag of words classique réduite par ACP : 'vectorized_corpus_count_reduced' | Nombre de features : 300\n",
      "--------------------------------------------------\n",
      "- Bag of words TF-IDF : 'vectorized_corpus_count' | Nombre de features : 500\n",
      "- Bag of words TF-IDF réduite par ACP : 'vectorized_corpus_ftidf_reduced' | Nombre de features : 400\n",
      "--------------------------------------------------\n",
      "- Word2Vec : 'word2vec_embedded' | Nombre de features : 100\n",
      "--------------------------------------------------\n",
      "- BERT : 'features_bert' | Nombre de features : 768\n",
      "- BERT réduite par ACP : 'features_bert_reduced' | Nombre de features : 200\n",
      "--------------------------------------------------\n",
      "- USE : 'features_USE' | Nombre de features : 512\n",
      "- USE réduite par ACP : 'features_USE_reduced' | Nombre de features : 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Bag of words classique : 'vectorized_corpus_count' | Nombre de features : {vectorized_corpus_count.shape[1]}\")\n",
    "print(f\"- Bag of words classique réduite par ACP : 'vectorized_corpus_count_reduced' | Nombre de features : {vectorized_corpus_count_reduced.shape[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"- Bag of words TF-IDF : 'vectorized_corpus_count' | Nombre de features : {vectorized_corpus_ftidf.shape[1]}\")\n",
    "print(f\"- Bag of words TF-IDF réduite par ACP : 'vectorized_corpus_ftidf_reduced' | Nombre de features : {vectorized_corpus_ftidf_reduced.shape[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"- Word2Vec : 'word2vec_embedded' | Nombre de features : {word2vec_embedded.shape[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"- BERT : 'features_bert' | Nombre de features : {features_bert.shape[1]}\")\n",
    "print(f\"- BERT réduite par ACP : 'features_bert_reduced' | Nombre de features : {features_bert_reduced.shape[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"- USE : 'features_USE' | Nombre de features : {features_USE.shape[1]}\")\n",
    "print(f\"- USE réduite par ACP : 'features_USE_reduced' | Nombre de features : {features_USE_reduced.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5). Approches supervisées**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Définition de nos fonctions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction pour calculer la qualité de nos tags prédits (identique à celle utilisée pour nos approches non supervisées), donne les métriques suivantes :**\n",
    "\n",
    "- **Accuracy score** : proportion d'échantillons pour lesquels toutes les étiquettes sont prédites correctement.\n",
    "- **Precision score** : proportion des étiquettes prédites correctement par rapport à toutes les étiquettes prédites.\n",
    "- **Recall score** : proportion de vrais positifs parmi toutes les étiquettes réelles.\n",
    "- **F1 score** : moyenne pondérée de la précision et du rappel.\n",
    "- **Hamming loss** : fraction des étiquettes qui ne sont pas correctement prédites par rapport au nombre total d'étiquettes, plus c'est faible, meilleur c'est.\n",
    "- Documents avec **au moins un tag réel trouvé**.\n",
    "- Documents avec **tous les tags réels trouvés** (même si d'autres tags sont prédits en plus).\n",
    "- **Taux de couverture moyen** : moyenne de la proportion de tags réels trouvés pour chaque document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_quality(predict, real, txt=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Cette fonction permet d'évaluer la qualité de nos prédictions de tags\n",
    "    -------------------\n",
    "    predict : les tags prédits (sous forme de liste de liste, ou array de liste)\n",
    "    real : les tags réels (sous forme de liste de liste, ou array de liste)\n",
    "    txt (défaut : True) : si les tags ne sont pas vectorisés, ils le seront avec MultiLabelBinarizer\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Création d'un dictionnaire pour stocker nos métriques\n",
    "    metriques = {}\n",
    "\n",
    "    print(\"---------- Métriques classiques ----------\")\n",
    "          \n",
    "    ##########################################\n",
    "    # Métriques de classification classiques #\n",
    "    ##########################################\n",
    "\n",
    "    # Si les données sont sous forme de texte, il faut les vectoriser\n",
    "    # pour calculer les métriques, je le fais avec MultiLabelBinarizer\n",
    "    if txt:\n",
    "        # Si la prédiction est non supervisée, cela crée des tags qui n'existent pas\n",
    "        # dans les tags réels, ce qui va provoquer un warning\n",
    "        # de MultiLabelBinarizer, disant qu'il va ignorer ces tags.\n",
    "        # je désactive temporairement ce UserWarning\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        real_bin = mlb.fit_transform(real)\n",
    "        predict_bin = mlb.transform(predict)\n",
    "\n",
    "        warnings.filterwarnings(\"default\", category=UserWarning)\n",
    "    else:\n",
    "        real_bin = real\n",
    "        predict_bin = predict\n",
    "\n",
    "    accuracy_score_value = accuracy_score(real_bin, predict_bin)\n",
    "    print(f\"Accuracy score : {accuracy_score_value:.3f}\")\n",
    "    metriques['Accuracy score'] = accuracy_score_value\n",
    "\n",
    "    # zero_division=0 : si une classe n'est pas du tout prédite correctement, la précision pour cette classe sera fixée à 0\n",
    "    # average='weighted' : agrégation pondérée, car les classes ne sont pas équilibrées (certaines sont beaucoup plus fréquentes que d'autres)\n",
    "    precision_score_value = precision_score(real_bin, predict_bin, average='weighted', zero_division=0)\n",
    "    print(f\"Precision score : {precision_score_value:.3f}\")\n",
    "    metriques['Precision score'] = precision_score_value\n",
    "\n",
    "    recall_score_value = recall_score(real_bin, predict_bin, average='weighted')\n",
    "    print(f\"Recall score : {recall_score_value:.3f}\")\n",
    "    metriques['Recall score'] = recall_score_value\n",
    "\n",
    "    f1_score_value = f1_score(real_bin, predict_bin, average='weighted')\n",
    "    print(f\"F1 score : {f1_score_value:.3f}\")\n",
    "    metriques['F1 score'] = f1_score_value\n",
    "\n",
    "    hamming_loss_value = hamming_loss(real_bin, predict_bin)\n",
    "    print(f\"Hamming loss : {hamming_loss_value:.3f}\")\n",
    "    metriques['Hamming loss'] = hamming_loss_value\n",
    "\n",
    "    print(\"---------- Métriques métier ----------\")\n",
    "\n",
    "    #################################################################################\n",
    "    # Cas avec au moins un mot en commun entre les tags réels et les tags prédits : #\n",
    "    #################################################################################\n",
    "\n",
    "    # Variable qui sera incrémentée à chaque fois\n",
    "    # qu'il y aura un mot en commun entre prédiction et réel\n",
    "    common_word_count = 0\n",
    "\n",
    "    for predict_tag, real_tag in zip(predict, real):\n",
    "\n",
    "        # Je convertis en set pour pouvoir facilement comparer ensuite\n",
    "        predict_tag = set(predict_tag)\n",
    "        real_tag = set(real_tag)\n",
    "        \n",
    "        # 'predict & real' retourne un set contenant les valeurs communes\n",
    "        # entre les deux s'il y en a. Sinon un set vide sera retourné\n",
    "        if predict_tag & real_tag:\n",
    "            common_word_count += 1\n",
    "\n",
    "    # Calculer le pourcentage de cas où il y a au moins un mot en commun\n",
    "    total_cases = len(real)  # Autrement dit, le nombre de documents\n",
    "                             # en considérant qu'il y a des tags réels\n",
    "                             # pour tous les documents\n",
    "    percentage_common_word_cases = (common_word_count / total_cases) * 100\n",
    "    print(f\"Documents avec au moins un tag réel trouvé : {percentage_common_word_cases:.2f} %\")\n",
    "    metriques['Au moins un tags réel'] = percentage_common_word_cases\n",
    "\n",
    "    ###################################################################\n",
    "    # Cas où tous les tags réels apparaissent dans les tags prédits : #\n",
    "    ###################################################################\n",
    "\n",
    "    # Variable qui sera incrémentée à chaque fois que tous\n",
    "    # les tags réels se trouveront dans les tags prédits\n",
    "    all_found_count = 0\n",
    "\n",
    "    for predict_tag, real_tag in zip(predict, real):\n",
    "\n",
    "        # Je convertis en set pour pouvoir facilement comparer ensuite\n",
    "        predict_tag = set(predict_tag)\n",
    "        real_tag = set(real_tag)\n",
    "\n",
    "        # real_tag <= predict_tag retourne True si tout le contenu\n",
    "        # de real_tag est présent dans predict_tag\n",
    "        if real_tag <= predict_tag:\n",
    "            all_found_count += 1\n",
    "\n",
    "    # On reprend total_cases calculé précédemment\n",
    "    percentage_all_found_count = (all_found_count / total_cases) * 100\n",
    "    print(f\"Documents avec tous les tags réels trouvés : {percentage_all_found_count:.2f} %\")\n",
    "    metriques['Tous les tags réels'] = percentage_all_found_count\n",
    "\n",
    "    ######################################\n",
    "    # Calcul du taux de couverture moyen #\n",
    "    ######################################\n",
    "\n",
    "    # Les taux de couverture locaux seront stockés dans cette liste,\n",
    "    # dans les cas supérieurs à 0 (au moins un tag trouvé)\n",
    "    all_taux_couv = []\n",
    "\n",
    "    for predict_tag, real_tag in zip(predict, real):\n",
    "\n",
    "        # Je convertis en set pour pouvoir facilement comparer ensuite\n",
    "        predict_tag = set(predict_tag)\n",
    "        real_tag = set(real_tag)\n",
    "\n",
    "        couv = real_tag & predict_tag  # Retourne les mots en commun entre les deux,\n",
    "                                       # retourne un set vide si rien en commun\n",
    "    \n",
    "        if couv:  # Donc set non vide, au moins un mot en commun\n",
    "            # Le nombre de mots en commun / le nombre total de tags réels\n",
    "            all_taux_couv.append(len(couv)/len(real_tag))\n",
    "        \n",
    "    # On reprend total_cases calculé précédemment.\n",
    "    # On divise bien par le total et non par all_taux_couv\n",
    "    # car all_taux_couv ne contient que les valeurs\n",
    "    # des cas où au moins un tag réel est trouvé\n",
    "    taux_couv_moyen = (sum(all_taux_couv) / total_cases) * 100\n",
    "    print(f\"Taux de couverture moyen : {taux_couv_moyen:.2f} %\")\n",
    "    metriques['Couverture'] = taux_couv_moyen\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Proportion d'absence de prédiction #\n",
    "    ######################################\n",
    "\n",
    "    # Nombre de documents qui n'ont pas de tags prédits\n",
    "    docs_sans_tags_pred = sum(1 for sous_liste in predict if not sous_liste)\n",
    "\n",
    "    # Pourcentage concerné\n",
    "    absence_predict = docs_sans_tags_pred / len(predict) * 100\n",
    "\n",
    "    # Je précise le nombre de documents concernés s'il y en a\n",
    "    # qui n'ont pas de tags\n",
    "    if docs_sans_tags_pred:\n",
    "        docs_concernes = f\" ({docs_sans_tags_pred} documents)\"\n",
    "    else:\n",
    "        docs_concernes = \"\"\n",
    "\n",
    "    print(f\"Documents sans prédiction de tags : {absence_predict:.2f} %{docs_concernes}\")\n",
    "    metriques['Sans prédiction'] = absence_predict\n",
    "\n",
    "    return metriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction pour lancer et évaluer le modèle supervisé de notre choix, elle réalise les tâches suivantes :**\n",
    "\n",
    "- Split des données en train et test avec train_test_split (Scikit-Learn)\n",
    "- Encodage des étiquettes avec MultiLabelBinarizer (Scikit-Learn)\n",
    "- Entrainement du modèle et prédiction sur test\n",
    "- Évaluation des résultats avec predict_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_eval_model(X,\n",
    "                       y,\n",
    "                       model,\n",
    "                       parametres=None,\n",
    "                       return_pred_tags=False,\n",
    "                       seed_value=None,\n",
    "                       test_size=0.2,\n",
    "                       log_run=False,\n",
    "                       log_model=False,\n",
    "                       description=None\n",
    "                       ):\n",
    "    \n",
    "    if seed_value:\n",
    "        seed_value = seed_value\n",
    "    else:\n",
    "        seed_value = None\n",
    "\n",
    "    if type(X) != str:\n",
    "        print(\"L'argument X doit être passé sous forme de string.\")\n",
    "        return\n",
    "\n",
    "    # L'intérêt de passer au format string les données utilisées\n",
    "    # est qu'on peut l'indiquer au moment d'exécuter la fonction\n",
    "    vectorisation = X\n",
    "    print(f\"Données utilisées : {vectorisation}\")\n",
    "\n",
    "    # Récupérer la variable en faisant un eval sur le string de son nom\n",
    "    X = eval(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=seed_value,  # Pour des résultats reproductibles\n",
    "                                                        stratify=None  # Vu toutes les combinaisons de tags,\n",
    "                                                                    # pas possible de stratifier\n",
    "                                    )\n",
    "\n",
    "    # Encodage des labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_train_bin = mlb.fit_transform(y_train)\n",
    "    y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "    # Vérifier s'il y a des tags présents dans test sans l'être dans train\n",
    "    classes_y_train = set()  # Set avec les classes uniques de y_train\n",
    "    for item in y_train:\n",
    "        classes_y_train.update(item)\n",
    "    classes_y_test = set()  # Set avec les classes uniques de y_test\n",
    "    for item in y_test:\n",
    "        classes_y_test.update(item)\n",
    "    classes_absentes = classes_y_test - classes_y_train  # Retourne les élements du set classes_y_test\n",
    "                                                         # qui ne sont pas présents dans le set classes_y_train\n",
    "    if classes_absentes:\n",
    "        # Tags présents dans test et absents dans train, tous documents confondus : \n",
    "        print(f\"Attention, {len(classes_absentes)} tags sont présents dans test et pas dans train : {classes_absentes}\")\n",
    "        # Documents de test qui ne possèdent que des tags absents de train\n",
    "        # L'encodage de MultiLabelBinarizer ne contiendra alors que des 0,\n",
    "        # ce qui rendra imposssible les prévisions supervisées pour ces documents :\n",
    "        num_zero_rows = np.count_nonzero((y_test_bin == 0).all(axis=1))\n",
    "        print(f\"Documents de test avec que des tags absents de train : {num_zero_rows}\")\n",
    "\n",
    "    nom_modele = type(model).__name__\n",
    "    print(f\"Modèle utilisé : {nom_modele}\")\n",
    "\n",
    "    # Instanciation et paramétrage\n",
    "    mdl = model.set_params(**parametres)\n",
    "\n",
    "    # Entraînement\n",
    "    print(\"Entraînement...\", end=\" \", flush=True)\n",
    "    lancement = time.time()\n",
    "    mdl.fit(X_train, y_train_bin)\n",
    "    fit_time = time.time() - lancement\n",
    "    print(\"Terminé\")\n",
    "\n",
    "    # Prédiction sur set de test\n",
    "    print(\"Prédictions...\", end=\" \", flush=True)\n",
    "    lancement = time.time()\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    pred_time = time.time() - lancement\n",
    "    print(\"Terminé\")\n",
    "\n",
    "    # Affichage des durées\n",
    "    print(f\"Durées d'exécution : {fit_time:.1f} s (entraînement), {pred_time:.1f} s (prédictions).\")\n",
    "\n",
    "    # On inverse transforme les tags pour récupérer les valeurs textuelles\n",
    "    y_pred_tags = mlb.inverse_transform(y_pred)\n",
    "    y_pred_tags_list = [list(tags) for tags in y_pred_tags]\n",
    "    y_test_tags = mlb.inverse_transform(y_test_bin)\n",
    "    y_test_tags_list = [list(tags) for tags in y_test_tags]\n",
    "\n",
    "    # Évaluation de la qualité des prédictions\n",
    "    # On récupère toutes les métriques (dictionnaire)\n",
    "    metriques = predict_quality(y_pred_tags_list, y_test_tags_list, txt=True)\n",
    "\n",
    "    # Si on a choisi de loger notre run dans ML Flow\n",
    "    if log_run:\n",
    "        # J'ajoute les durées de fit et predict dans le\n",
    "        # dictionnaire metriques pour les loguer également\n",
    "        metriques['Fit time'] = fit_time\n",
    "        metriques['Predict time'] = pred_time\n",
    "        mlflow.set_experiment(\"Approche supervisée\")\n",
    "        run_name = f\"{nom_modele}_{int(time.time())}\"\n",
    "        with mlflow.start_run(run_name=run_name, description=description):\n",
    "            # Si des hyperparamètres spécifiques ont été passés pour le modèle\n",
    "            # alors loguer ces derniers dans ML Flow\n",
    "            if parametres:\n",
    "                mlflow.log_params(parametres)\n",
    "            # log_param sans \"s\" car un seul paramètre\n",
    "            mlflow.log_param(\"Vectorisation\", vectorisation)\n",
    "            # On log les métriques du dictionnaire dans ML Flow\n",
    "            mlflow.log_metrics(metriques)\n",
    "            # Si l'option est activée, alors enregistrer le modèle\n",
    "            if log_model:\n",
    "                # Enregistrement du modèle\n",
    "                mlflow.sklearn.log_model(mdl, nom_modele)\n",
    "\n",
    "    if return_pred_tags:\n",
    "        return y_pred_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A). KNeighborsClassifier (Scikit-Learn)**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<i>KNeighborsClassifier</i> étant un modèle rapide à exécuter, je laisse dans le notebook les exécutions avec tous les types de vectorisations pour comparaison. Pour les modèles suivants, je ne laisserai que les exécutions avec les vectorisations qui ont apporté les meilleurs résultats. <i>XGBClassifier</i> (XGBoost) avait été initialement testé mais a été supprimé de ce notebook en raison de résultats peu satisfaisants et de temps d'exécution très longs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec bag of words classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : vectorized_corpus_count\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 7.5 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.057\n",
      "Precision score : 0.191\n",
      "Recall score : 0.176\n",
      "F1 score : 0.180\n",
      "Hamming loss : 0.015\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 26.66 %\n",
      "Documents avec tous les tags réels trouvés : 11.49 %\n",
      "Taux de couverture moyen : 18.39 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,   \n",
    "          'weights': 'distance' # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'vectorized_corpus_count'  # On passe en string, comme ça la fonction pourra\n",
    "                                            # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec bag of words classique ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : vectorized_corpus_count_reduced\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 1.3 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.054\n",
      "Precision score : 0.179\n",
      "Recall score : 0.169\n",
      "F1 score : 0.172\n",
      "Hamming loss : 0.015\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 25.61 %\n",
      "Documents avec tous les tags réels trouvés : 10.76 %\n",
      "Taux de couverture moyen : 17.54 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,   \n",
    "          'weights': 'distance' # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'vectorized_corpus_count_reduced'  # On passe en string, comme ça la fonction pourra\n",
    "                                                    # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec bag of words TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : vectorized_corpus_ftidf\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 10.8 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.072\n",
      "Precision score : 0.237\n",
      "Recall score : 0.228\n",
      "F1 score : 0.230\n",
      "Hamming loss : 0.014\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 34.13 %\n",
      "Documents avec tous les tags réels trouvés : 15.05 %\n",
      "Taux de couverture moyen : 23.87 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,   \n",
    "          'weights': 'distance' # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'vectorized_corpus_ftidf'  # On passe en string, comme ça la fonction pourra\n",
    "                                            # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec bag of words TF-IDF ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : vectorized_corpus_ftidf_reduced\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 1.5 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.073\n",
      "Precision score : 0.234\n",
      "Recall score : 0.223\n",
      "F1 score : 0.226\n",
      "Hamming loss : 0.014\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 33.46 %\n",
      "Documents avec tous les tags réels trouvés : 14.73 %\n",
      "Taux de couverture moyen : 23.38 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,   \n",
    "          'weights': 'distance' # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'vectorized_corpus_ftidf_reduced'  # On passe en string, comme ça la fonction pourra\n",
    "                                                    # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : word2vec_embedded\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 0.5 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.099\n",
      "Precision score : 0.300\n",
      "Recall score : 0.304\n",
      "F1 score : 0.300\n",
      "Hamming loss : 0.013\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 44.46 %\n",
      "Documents avec tous les tags réels trouvés : 20.74 %\n",
      "Taux de couverture moyen : 31.90 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,\n",
    "          'algorithm': 'auto',\n",
    "          'weights': 'distance', # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                 # pour des résultats équivalents.\n",
    "          'leaf_size': 30,\n",
    "          'p': 2,\n",
    "          'n_jobs': workers_to_use,\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'word2vec_embedded'  # On passe en string, comme ça la fonction pourra\n",
    "                                      # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_bert\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 3.6 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.056\n",
      "Precision score : 0.190\n",
      "Recall score : 0.197\n",
      "F1 score : 0.191\n",
      "Hamming loss : 0.015\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 29.17 %\n",
      "Documents avec tous les tags réels trouvés : 12.57 %\n",
      "Taux de couverture moyen : 20.28 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,\n",
    "          'algorithm': 'auto',\n",
    "          'weights': 'distance', # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                 # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_bert'  # On passe en string, comme ça la fonction pourra\n",
    "                                  # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec BERT ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_bert_reduced\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 1.0 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.054\n",
      "Precision score : 0.181\n",
      "Recall score : 0.188\n",
      "F1 score : 0.183\n",
      "Hamming loss : 0.015\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 27.87 %\n",
      "Documents avec tous les tags réels trouvés : 12.02 %\n",
      "Taux de couverture moyen : 19.35 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,\n",
    "          'algorithm': 'auto',\n",
    "          'weights': 'distance', # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                 # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_bert_reduced'  # On passe en string, comme ça la fonction pourra\n",
    "                                          # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_USE\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 2.5 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.165\n",
      "Precision score : 0.428\n",
      "Recall score : 0.446\n",
      "F1 score : 0.434\n",
      "Hamming loss : 0.011\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 63.26 %\n",
      "Documents avec tous les tags réels trouvés : 32.30 %\n",
      "Taux de couverture moyen : 47.36 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,\n",
    "          'algorithm': 'auto',\n",
    "          'weights': 'distance', # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                 # pour des résultats équivalents.\n",
    "          'leaf_size': 30,\n",
    "          'p': 2,\n",
    "          'n_jobs': workers_to_use,\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_USE'  # On passe en string, comme ça la fonction pourra\n",
    "                                 # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run,\n",
    "                   log_model=save_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec USE ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_USE_reduced\n",
      "Modèle utilisé : KNeighborsClassifier\n",
      "Entraînement... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 0.4 s (entraînement), 1.0 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.164\n",
      "Precision score : 0.428\n",
      "Recall score : 0.448\n",
      "F1 score : 0.435\n",
      "Hamming loss : 0.011\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 63.35 %\n",
      "Documents avec tous les tags réels trouvés : 32.57 %\n",
      "Taux de couverture moyen : 47.53 %\n",
      "Documents sans prédiction de tags : 0.00 %\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_neighbors': 1,\n",
    "          'algorithm': 'auto',\n",
    "          'weights': 'distance', # Par défaut 'uniform', qui entraîne un predict long\n",
    "                                 # pour des résultats équivalents.\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_USE_reduced'  # On passe en string, comme ça la fonction pourra\n",
    "                                         # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=KNeighborsClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B). LinearSVC avec OneVsRestClassifier (Scikit-Learn)**\n",
    "\n",
    "*Afin de ne pas alourdir inutilement le notebook (plusieurs heures de run), seule l'exécution avec la vectorisation apportant les meilleurs résultats est conservée.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_USE\n",
      "Modèle utilisé : OneVsRestClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 54.0 s (entraînement), 3.0 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.258\n",
      "Precision score : 0.737\n",
      "Recall score : 0.431\n",
      "F1 score : 0.524\n",
      "Hamming loss : 0.006\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 63.22 %\n",
      "Documents avec tous les tags réels trouvés : 31.87 %\n",
      "Taux de couverture moyen : 46.84 %\n",
      "Documents sans prédiction de tags : 29.88 % (2779 documents)\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_jobs': workers_to_use,\n",
    "          \n",
    "}\n",
    "\n",
    "paramsSVC = {'tol': 1e-4,\n",
    "             'C': 1,\n",
    "             'multi_class': 'ovr',\n",
    "             'max_iter': 1000\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_USE'  # On passe en string, comme ça la fonction pourra\n",
    "                                 # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=OneVsRestClassifier(LinearSVC(**paramsSVC)),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run,\n",
    "                   log_model=save_model,\n",
    "                   description=\"Avec LinearSVC\" + str(paramsSVC)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **C). RandomForestClassifier (Scikit-Learn)**\n",
    "\n",
    "*Afin de ne pas alourdir inutilement le notebook (plusieurs heures de run), seule l'exécution avec la vectorisation apportant les meilleurs résultats est conservée.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec bag of words classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : vectorized_corpus_count\n",
      "Modèle utilisé : RandomForestClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 39.1 s (entraînement), 2.7 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.112\n",
      "Precision score : 0.566\n",
      "Recall score : 0.193\n",
      "F1 score : 0.264\n",
      "Hamming loss : 0.008\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 31.38 %\n",
      "Documents avec tous les tags réels trouvés : 12.43 %\n",
      "Taux de couverture moyen : 20.99 %\n",
      "Documents sans prédiction de tags : 63.00 % (5859 documents)\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_jobs': workers_to_use,\n",
    "          'n_estimators': 50,\n",
    "          'max_depth': None,\n",
    "          'max_features': 'sqrt',\n",
    "          'min_samples_leaf': 1,\n",
    "          'min_samples_split': 2,\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'vectorized_corpus_count'  # On passe en string, comme ça la fonction pourra\n",
    "                                            # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=RandomForestClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run,\n",
    "                   log_model=False  # Très volumineux à stocker, donc on ne l'enregistre pas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D). LogisticRegression avec OneVsRestClassifier (Scikit-Learn)**\n",
    "\n",
    "*Afin de ne pas alourdir inutilement le notebook (plusieurs heures de run), seule l'exécution avec la vectorisation apportant les meilleurs résultats est conservée.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec USE ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_USE_reduced\n",
      "Modèle utilisé : OneVsRestClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... Terminé\n",
      "Durées d'exécution : 30.2 s (entraînement), 0.3 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.236\n",
      "Precision score : 0.664\n",
      "Recall score : 0.482\n",
      "F1 score : 0.551\n",
      "Hamming loss : 0.007\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 67.94 %\n",
      "Documents avec tous les tags réels trouvés : 36.65 %\n",
      "Taux de couverture moyen : 51.85 %\n",
      "Documents sans prédiction de tags : 21.19 % (1971 documents)\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'n_jobs': workers_to_use\n",
    "}\n",
    "\n",
    "paramsLog = {'tol': 1e-4,\n",
    "             'C': 1000,\n",
    "             'max_iter': 50,\n",
    "             'solver': 'newton-cholesky',\n",
    "             'n_jobs': workers_to_use,\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_USE_reduced'  # On passe en string, comme ça la fonction pourra\n",
    "                                         # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=OneVsRestClassifier(LogisticRegression(**paramsLog)),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run,\n",
    "                   log_model=save_model,\n",
    "                   description=\"Avec LogisticRegression\\n\" + str(paramsLog)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **E). MLPClassifier (Scikit-Learn)**\n",
    "\n",
    "*Afin de ne pas alourdir inutilement le notebook (plusieurs heures de run), seules les exécutions avec les vectorisations apportant les meilleurs résultats sont conservées.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données utilisées : features_USE\n",
      "Modèle utilisé : MLPClassifier\n",
      "Entraînement... Terminé\n",
      "Prédictions... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Data Science\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé\n",
      "Durées d'exécution : 76.4 s (entraînement), 0.0 s (prédictions).\n",
      "---------- Métriques classiques ----------\n",
      "Accuracy score : 0.268\n",
      "Precision score : 0.694\n",
      "Recall score : 0.502\n",
      "F1 score : 0.569\n",
      "Hamming loss : 0.006\n",
      "---------- Métriques métier ----------\n",
      "Documents avec au moins un tag réel trouvé : 70.55 %\n",
      "Documents avec tous les tags réels trouvés : 38.06 %\n",
      "Taux de couverture moyen : 53.86 %\n",
      "Documents sans prédiction de tags : 19.20 % (1786 documents)\n"
     ]
    }
   ],
   "source": [
    "# On précise les paramètres à utiliser avec le modèle : \n",
    "\n",
    "params = {'activation': 'relu',\n",
    "          'solver': 'adam',\n",
    "          'alpha': 1e-5,\n",
    "          'batch_size': 50,\n",
    "          'max_iter': 50,\n",
    "          'tol': 1e-4,\n",
    "          'random_state': seed_value,\n",
    "}\n",
    "\n",
    "# On précise quelle vectorisation du corpus on souhaite utiliser : \n",
    "\n",
    "encoded_corpus = 'features_USE'  # On passe en string, comme ça la fonction pourra\n",
    "                                 # indiquer les données utilisées lors de son exécution\n",
    "\n",
    "# Lancement de notre pipeline\n",
    "run_and_eval_model(X=encoded_corpus,\n",
    "                   y=data['tags'],\n",
    "                   model=MLPClassifier(),\n",
    "                   parametres=params,\n",
    "                   return_pred_tags=False,\n",
    "                   seed_value=seed_value,\n",
    "                   log_run=do_log_run,\n",
    "                   log_model=save_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des résultats un peu meilleurs peuvent être obtenus en modifiant certains hyperparamètres, notamment en augmentant *max_iter*, mais au prix d'une durée de fit beaucoup plus longue. Dans tous les cas, il n'a pas été possible d'avoir un résultat sans aucune absence de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Résultats préliminaires sur toutes les vectorisations**\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Le notebook a été allégé car son exécution prenait plusieurs heures. Voici les résultats des tests préliminaires des modèles sur toutes les vectorisations : \n",
    "</div>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Modèle</td>\n",
    "        <td>Vectorisation</td>\n",
    "        <td>Fit</td>\n",
    "        <td>Predict</td>\n",
    "        <td>Accuracy score</td>\n",
    "        <td>Precision score</td>\n",
    "        <td>Recall score</td>\n",
    "        <td>F1 score</td>\n",
    "        <td>Hamming loss</td>\n",
    "        <td>Documents avec au moins un tag réel trouvé</td>\n",
    "        <td>Documents avec tous les tags réels trouvés</td>\n",
    "        <td>Taux de couverture moyen</td>\n",
    "        <td>Documents sans prédiction de tags</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>vectorized_corpus_count</td>\n",
    "        <td>0,3</td>\n",
    "        <td>7,2</td>\n",
    "        <td>0,057</td>\n",
    "        <td>0,191</td>\n",
    "        <td>0,176</td>\n",
    "        <td>0,18</td>\n",
    "        <td>0,015</td>\n",
    "        <td>26,66</td>\n",
    "        <td>11,49</td>\n",
    "        <td>18,39</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>0,4</td>\n",
    "        <td>1,6</td>\n",
    "        <td>0,054</td>\n",
    "        <td>0,179</td>\n",
    "        <td>0,169</td>\n",
    "        <td>0,172</td>\n",
    "        <td>0,015</td>\n",
    "        <td>25,61</td>\n",
    "        <td>10,76</td>\n",
    "        <td>17,54</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>0,3</td>\n",
    "        <td>17</td>\n",
    "        <td>0,072</td>\n",
    "        <td>0,237</td>\n",
    "        <td>0,228</td>\n",
    "        <td>0,23</td>\n",
    "        <td>0,014</td>\n",
    "        <td>34,13</td>\n",
    "        <td>15,05</td>\n",
    "        <td>23,87</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>0,3</td>\n",
    "        <td>1,8</td>\n",
    "        <td>0,073</td>\n",
    "        <td>0,234</td>\n",
    "        <td>0,223</td>\n",
    "        <td>0,226</td>\n",
    "        <td>0,014</td>\n",
    "        <td>33,46</td>\n",
    "        <td>14,73</td>\n",
    "        <td>23,38</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>0,3</td>\n",
    "        <td>0,7</td>\n",
    "        <td>0,099</td>\n",
    "        <td>0,3</td>\n",
    "        <td>0,304</td>\n",
    "        <td>0,3</td>\n",
    "        <td>0,013</td>\n",
    "        <td>44,46</td>\n",
    "        <td>20,74</td>\n",
    "        <td>31,90</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>0,3</td>\n",
    "        <td>3,8</td>\n",
    "        <td>0,056</td>\n",
    "        <td>0,19</td>\n",
    "        <td>0,197</td>\n",
    "        <td>0,191</td>\n",
    "        <td>0,015</td>\n",
    "        <td>29,17</td>\n",
    "        <td>12,57</td>\n",
    "        <td>20,28</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>0,3</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,054</td>\n",
    "        <td>0,181</td>\n",
    "        <td>0,188</td>\n",
    "        <td>0,183</td>\n",
    "        <td>0,015</td>\n",
    "        <td>27,87</td>\n",
    "        <td>12,02</td>\n",
    "        <td>19,35</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>0,3</td>\n",
    "        <td>2,6</td>\n",
    "        <td>0,165</td>\n",
    "        <td>0,428</td>\n",
    "        <td>0,446</td>\n",
    "        <td>0,434</td>\n",
    "        <td>0,011</td>\n",
    "        <td>63,26</td>\n",
    "        <td>32,30</td>\n",
    "        <td>47,36</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>KNeighborsClassifier</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>0,3</td>\n",
    "        <td>1,2</td>\n",
    "        <td>0,164</td>\n",
    "        <td>0,428</td>\n",
    "        <td>0,448</td>\n",
    "        <td>0,435</td>\n",
    "        <td>0,011</td>\n",
    "        <td>63,35</td>\n",
    "        <td>32,57</td>\n",
    "        <td>47,53</td>\n",
    "        <td>0,00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>469,7</td>\n",
    "        <td>0,8</td>\n",
    "        <td>0,097</td>\n",
    "        <td>0,529</td>\n",
    "        <td>0,191</td>\n",
    "        <td>0,266</td>\n",
    "        <td>0,008</td>\n",
    "        <td>30,06</td>\n",
    "        <td>12,74</td>\n",
    "        <td>20,59</td>\n",
    "        <td>63,85</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>5,3</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,122</td>\n",
    "        <td>0,596</td>\n",
    "        <td>0,225</td>\n",
    "        <td>0,306</td>\n",
    "        <td>0,008</td>\n",
    "        <td>34,85</td>\n",
    "        <td>14,78</td>\n",
    "        <td>24,00</td>\n",
    "        <td>58,56</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>44,9</td>\n",
    "        <td>1</td>\n",
    "        <td>0,12</td>\n",
    "        <td>0,569</td>\n",
    "        <td>0,219</td>\n",
    "        <td>0,298</td>\n",
    "        <td>0,008</td>\n",
    "        <td>34,08</td>\n",
    "        <td>14,45</td>\n",
    "        <td>23,44</td>\n",
    "        <td>59,71</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>91,2</td>\n",
    "        <td>0,6</td>\n",
    "        <td>0,106</td>\n",
    "        <td>0,613</td>\n",
    "        <td>0,198</td>\n",
    "        <td>0,281</td>\n",
    "        <td>0,008</td>\n",
    "        <td>30,96</td>\n",
    "        <td>13,46</td>\n",
    "        <td>21,45</td>\n",
    "        <td>64,59</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>543,6</td>\n",
    "        <td>4,4</td>\n",
    "        <td>0,163</td>\n",
    "        <td>0,672</td>\n",
    "        <td>0,338</td>\n",
    "        <td>0,433</td>\n",
    "        <td>0,008</td>\n",
    "        <td>50,25</td>\n",
    "        <td>23,35</td>\n",
    "        <td>35,99</td>\n",
    "        <td>39,09</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>144,1</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,097</td>\n",
    "        <td>0,687</td>\n",
    "        <td>0,188</td>\n",
    "        <td>0,271</td>\n",
    "        <td>0,008</td>\n",
    "        <td>29,74</td>\n",
    "        <td>11,70</td>\n",
    "        <td>19,86</td>\n",
    "        <td>64,15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>49</td>\n",
    "        <td>2,9</td>\n",
    "        <td>0,258</td>\n",
    "        <td>0,737</td>\n",
    "        <td>0,431</td>\n",
    "        <td>0,524</td>\n",
    "        <td>0,006</td>\n",
    "        <td>63,22</td>\n",
    "        <td>31,87</td>\n",
    "        <td>46,84</td>\n",
    "        <td>29,88</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LinearSVC())</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>21,7</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,252</td>\n",
    "        <td>0,732</td>\n",
    "        <td>0,419</td>\n",
    "        <td>0,511</td>\n",
    "        <td>0,006</td>\n",
    "        <td>61,77</td>\n",
    "        <td>31,02</td>\n",
    "        <td>45,57</td>\n",
    "        <td>31,15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>vectorized_corpus_count</td>\n",
    "        <td>67,8</td>\n",
    "        <td>4,5</td>\n",
    "        <td>0,111</td>\n",
    "        <td>0,56</td>\n",
    "        <td>0,194</td>\n",
    "        <td>0,264</td>\n",
    "        <td>0,008</td>\n",
    "        <td>31,59</td>\n",
    "        <td>12,29</td>\n",
    "        <td>21,01</td>\n",
    "        <td>62,78</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>311,8</td>\n",
    "        <td>4,3</td>\n",
    "        <td>0,017</td>\n",
    "        <td>0,412</td>\n",
    "        <td>0,025</td>\n",
    "        <td>0,044</td>\n",
    "        <td>0,009</td>\n",
    "        <td>4,45</td>\n",
    "        <td>1,69</td>\n",
    "        <td>2,87</td>\n",
    "        <td>95,02</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>87,7</td>\n",
    "        <td>4,7</td>\n",
    "        <td>0,116</td>\n",
    "        <td>0,574</td>\n",
    "        <td>0,2</td>\n",
    "        <td>0,274</td>\n",
    "        <td>0,008</td>\n",
    "        <td>32,44</td>\n",
    "        <td>12,94</td>\n",
    "        <td>21,76</td>\n",
    "        <td>62,25</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>374,8</td>\n",
    "        <td>5,1</td>\n",
    "        <td>0,025</td>\n",
    "        <td>0,47</td>\n",
    "        <td>0,043</td>\n",
    "        <td>0,073</td>\n",
    "        <td>0,009</td>\n",
    "        <td>7,25</td>\n",
    "        <td>2,60</td>\n",
    "        <td>4,65</td>\n",
    "        <td>91,94</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>133,9</td>\n",
    "        <td>4,3</td>\n",
    "        <td>0,032</td>\n",
    "        <td>0,45</td>\n",
    "        <td>0,052</td>\n",
    "        <td>0,087</td>\n",
    "        <td>0,009</td>\n",
    "        <td>8,94</td>\n",
    "        <td>3,30</td>\n",
    "        <td>5,76</td>\n",
    "        <td>89,67</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>438,9</td>\n",
    "        <td>4,2</td>\n",
    "        <td>0</td>\n",
    "        <td>0,197</td>\n",
    "        <td>0,002</td>\n",
    "        <td>0,003</td>\n",
    "        <td>0,009</td>\n",
    "        <td>0,29</td>\n",
    "        <td>0,03</td>\n",
    "        <td>0,14</td>\n",
    "        <td>99,68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>236,5</td>\n",
    "        <td>4,3</td>\n",
    "        <td>0</td>\n",
    "        <td>0,115</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>0,009</td>\n",
    "        <td>0,04</td>\n",
    "        <td>0,01</td>\n",
    "        <td>0,03</td>\n",
    "        <td>99,96</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>279,8</td>\n",
    "        <td>4,1</td>\n",
    "        <td>0,087</td>\n",
    "        <td>0,553</td>\n",
    "        <td>0,14</td>\n",
    "        <td>0,207</td>\n",
    "        <td>0,008</td>\n",
    "        <td>23,02</td>\n",
    "        <td>9,01</td>\n",
    "        <td>15,27</td>\n",
    "        <td>74,16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>RandomForestClassifier</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>188,2</td>\n",
    "        <td>4,3</td>\n",
    "        <td>0,03</td>\n",
    "        <td>0,437</td>\n",
    "        <td>0,054</td>\n",
    "        <td>0,087</td>\n",
    "        <td>0,009</td>\n",
    "        <td>8,68</td>\n",
    "        <td>3,15</td>\n",
    "        <td>5,64</td>\n",
    "        <td>90,69</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>vectorized_corpus_count</td>\n",
    "        <td>33</td>\n",
    "        <td>0,2</td>\n",
    "        <td>0,116</td>\n",
    "        <td>0,598</td>\n",
    "        <td>0,252</td>\n",
    "        <td>0,335</td>\n",
    "        <td>0,008</td>\n",
    "        <td>37,16</td>\n",
    "        <td>16,62</td>\n",
    "        <td>26,28</td>\n",
    "        <td>56,66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>616,1</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,075</td>\n",
    "        <td>0,543</td>\n",
    "        <td>0,162</td>\n",
    "        <td>0,234</td>\n",
    "        <td>0,009</td>\n",
    "        <td>25,47</td>\n",
    "        <td>10,19</td>\n",
    "        <td>17,15</td>\n",
    "        <td>67,20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>52,7</td>\n",
    "        <td>0,3</td>\n",
    "        <td>0,122</td>\n",
    "        <td>0,612</td>\n",
    "        <td>0,252</td>\n",
    "        <td>0,336</td>\n",
    "        <td>0,008</td>\n",
    "        <td>37,60</td>\n",
    "        <td>16,46</td>\n",
    "        <td>26,34</td>\n",
    "        <td>55,37</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>804,7</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,095</td>\n",
    "        <td>0,567</td>\n",
    "        <td>0,199</td>\n",
    "        <td>0,278</td>\n",
    "        <td>0,008</td>\n",
    "        <td>30,61</td>\n",
    "        <td>13,00</td>\n",
    "        <td>21,03</td>\n",
    "        <td>60,57</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>217,6</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,107</td>\n",
    "        <td>0,617</td>\n",
    "        <td>0,22</td>\n",
    "        <td>0,308</td>\n",
    "        <td>0,008</td>\n",
    "        <td>33,65</td>\n",
    "        <td>14,22</td>\n",
    "        <td>23,13</td>\n",
    "        <td>57,86</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>1566,7</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,049</td>\n",
    "        <td>0,569</td>\n",
    "        <td>0,116</td>\n",
    "        <td>0,183</td>\n",
    "        <td>0,009</td>\n",
    "        <td>18,94</td>\n",
    "        <td>6,72</td>\n",
    "        <td>12,20</td>\n",
    "        <td>73,25</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>428,1</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,031</td>\n",
    "        <td>0,589</td>\n",
    "        <td>0,076</td>\n",
    "        <td>0,128</td>\n",
    "        <td>0,009</td>\n",
    "        <td>12,76</td>\n",
    "        <td>3,99</td>\n",
    "        <td>7,85</td>\n",
    "        <td>82,62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>1042,7</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,206</td>\n",
    "        <td>0,684</td>\n",
    "        <td>0,401</td>\n",
    "        <td>0,491</td>\n",
    "        <td>0,007</td>\n",
    "        <td>58,34</td>\n",
    "        <td>29,03</td>\n",
    "        <td>42,97</td>\n",
    "        <td>32,29</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBClassifier</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>426,7</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,177</td>\n",
    "        <td>0,695</td>\n",
    "        <td>0,337</td>\n",
    "        <td>0,438</td>\n",
    "        <td>0,007</td>\n",
    "        <td>50,24</td>\n",
    "        <td>23,34</td>\n",
    "        <td>35,92</td>\n",
    "        <td>41,23</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>92,3</td>\n",
    "        <td>0,8</td>\n",
    "        <td>0,096</td>\n",
    "        <td>0,509</td>\n",
    "        <td>0,219</td>\n",
    "        <td>0,296</td>\n",
    "        <td>0,009</td>\n",
    "        <td>33,19</td>\n",
    "        <td>14,65</td>\n",
    "        <td>23,25</td>\n",
    "        <td>58,85</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>5,7</td>\n",
    "        <td>0,1</td>\n",
    "        <td>0,114</td>\n",
    "        <td>0,597</td>\n",
    "        <td>0,21</td>\n",
    "        <td>0,294</td>\n",
    "        <td>0,008</td>\n",
    "        <td>32,69</td>\n",
    "        <td>13,99</td>\n",
    "        <td>22,55</td>\n",
    "        <td>60,87</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>57,4</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,112</td>\n",
    "        <td>0,586</td>\n",
    "        <td>0,206</td>\n",
    "        <td>0,289</td>\n",
    "        <td>0,008</td>\n",
    "        <td>31,99</td>\n",
    "        <td>13,69</td>\n",
    "        <td>22,07</td>\n",
    "        <td>61,63</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>26,2</td>\n",
    "        <td>0,6</td>\n",
    "        <td>0,104</td>\n",
    "        <td>0,587</td>\n",
    "        <td>0,211</td>\n",
    "        <td>0,298</td>\n",
    "        <td>0,008</td>\n",
    "        <td>31,69</td>\n",
    "        <td>14,80</td>\n",
    "        <td>22,64</td>\n",
    "        <td>63,20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>429,3</td>\n",
    "        <td>4,2</td>\n",
    "        <td>0,157</td>\n",
    "        <td>0,69</td>\n",
    "        <td>0,306</td>\n",
    "        <td>0,41</td>\n",
    "        <td>0,008</td>\n",
    "        <td>45,38</td>\n",
    "        <td>21,23</td>\n",
    "        <td>32,57</td>\n",
    "        <td>46,13</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>60,1</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,116</td>\n",
    "        <td>0,652</td>\n",
    "        <td>0,241</td>\n",
    "        <td>0,337</td>\n",
    "        <td>0,008</td>\n",
    "        <td>36,39</td>\n",
    "        <td>16,11</td>\n",
    "        <td>25,49</td>\n",
    "        <td>54,95</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>114,2</td>\n",
    "        <td>2,8</td>\n",
    "        <td>0,22</td>\n",
    "        <td>0,725</td>\n",
    "        <td>0,367</td>\n",
    "        <td>0,463</td>\n",
    "        <td>0,007</td>\n",
    "        <td>55,57</td>\n",
    "        <td>26,29</td>\n",
    "        <td>39,92</td>\n",
    "        <td>37,87</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OneVsRestClassifier(LogisticRegression())</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>42,9</td>\n",
    "        <td>1,1</td>\n",
    "        <td>0,216</td>\n",
    "        <td>0,721</td>\n",
    "        <td>0,364</td>\n",
    "        <td>0,459</td>\n",
    "        <td>0,007</td>\n",
    "        <td>55,15</td>\n",
    "        <td>26,00</td>\n",
    "        <td>39,57</td>\n",
    "        <td>38,31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>vectorized_corpus_count</td>\n",
    "        <td>70,4</td>\n",
    "        <td>0</td>\n",
    "        <td>0,128</td>\n",
    "        <td>0,5</td>\n",
    "        <td>0,32</td>\n",
    "        <td>0,383</td>\n",
    "        <td>0,009</td>\n",
    "        <td>46,70</td>\n",
    "        <td>21,89</td>\n",
    "        <td>33,60</td>\n",
    "        <td>36,11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>vectorized_corpus_count_reduced</td>\n",
    "        <td>72</td>\n",
    "        <td>0</td>\n",
    "        <td>0,122</td>\n",
    "        <td>0,499</td>\n",
    "        <td>0,286</td>\n",
    "        <td>0,354</td>\n",
    "        <td>0,009</td>\n",
    "        <td>42,09</td>\n",
    "        <td>19,26</td>\n",
    "        <td>29,96</td>\n",
    "        <td>43,04</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf</td>\n",
    "        <td>69,7</td>\n",
    "        <td>0</td>\n",
    "        <td>0,15</td>\n",
    "        <td>0,578</td>\n",
    "        <td>0,31</td>\n",
    "        <td>0,39</td>\n",
    "        <td>0,008</td>\n",
    "        <td>45,84</td>\n",
    "        <td>21,03</td>\n",
    "        <td>32,67</td>\n",
    "        <td>41,62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>vectorized_corpus_ftidf_reduced</td>\n",
    "        <td>74,2</td>\n",
    "        <td>0</td>\n",
    "        <td>0,15</td>\n",
    "        <td>0,58</td>\n",
    "        <td>0,303</td>\n",
    "        <td>0,382</td>\n",
    "        <td>0,008</td>\n",
    "        <td>44,69</td>\n",
    "        <td>20,61</td>\n",
    "        <td>31,93</td>\n",
    "        <td>43,52</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>word2vec_embedded</td>\n",
    "        <td>52,2</td>\n",
    "        <td>0</td>\n",
    "        <td>0,176</td>\n",
    "        <td>0,644</td>\n",
    "        <td>0,328</td>\n",
    "        <td>0,418</td>\n",
    "        <td>0,007</td>\n",
    "        <td>49,00</td>\n",
    "        <td>23,38</td>\n",
    "        <td>35,34</td>\n",
    "        <td>40,86</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>features_bert</td>\n",
    "        <td>72,4</td>\n",
    "        <td>0</td>\n",
    "        <td>0,155</td>\n",
    "        <td>0,638</td>\n",
    "        <td>0,33</td>\n",
    "        <td>0,422</td>\n",
    "        <td>0,008</td>\n",
    "        <td>48,04</td>\n",
    "        <td>22,78</td>\n",
    "        <td>34,78</td>\n",
    "        <td>40,40</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>features_bert_reduced</td>\n",
    "        <td>53,1</td>\n",
    "        <td>0</td>\n",
    "        <td>0,128</td>\n",
    "        <td>0,593</td>\n",
    "        <td>0,293</td>\n",
    "        <td>0,381</td>\n",
    "        <td>0,008</td>\n",
    "        <td>42,73</td>\n",
    "        <td>19,56</td>\n",
    "        <td>30,49</td>\n",
    "        <td>43,82</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>features_USE</td>\n",
    "        <td>56,5</td>\n",
    "        <td>0</td>\n",
    "        <td>0,266</td>\n",
    "        <td>0,701</td>\n",
    "        <td>0,492</td>\n",
    "        <td>0,566</td>\n",
    "        <td>0,006</td>\n",
    "        <td>69,86</td>\n",
    "        <td>37,04</td>\n",
    "        <td>52,92</td>\n",
    "        <td>20,37</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MLPClassifier</td>\n",
    "        <td>features_USE_reduced</td>\n",
    "        <td>52,3</td>\n",
    "        <td>0</td>\n",
    "        <td>0,263</td>\n",
    "        <td>0,7</td>\n",
    "        <td>0,487</td>\n",
    "        <td>0,563</td>\n",
    "        <td>0,006</td>\n",
    "        <td>69,62</td>\n",
    "        <td>36,46</td>\n",
    "        <td>52,51</td>\n",
    "        <td>20,69</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "On constate que c'est le plus souvent en utilisant la vectorisation avec USE (Universal Sentence Encoder) qu'on obtient les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6). Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mesure de la durée d'exécution du notebook : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durée d'exécution du notebook (hors imports) : 04:26\n"
     ]
    }
   ],
   "source": [
    "temps_secondes = time.time() - t_notebook\n",
    "\n",
    "# Conversion en minutes et secondes\n",
    "minutes = int(temps_secondes // 60)\n",
    "seconds = int(temps_secondes % 60)\n",
    "\n",
    "# Formatage du résultat\n",
    "formatted_time = f\"{minutes:02}:{seconds:02}\"\n",
    "\n",
    "print(f\"Durée d'exécution du notebook (hors imports) : {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
